{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/konstantinorlovskiy/opt/anaconda3/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import json\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from scipy.sparse import coo_matrix  # LightFM fit method requires coo matrix format as input.\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightfm.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Data Import and Cleaning - Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing Events data and sorting by timestamp column which corresponds the historical order of events.\n",
    "\n",
    "df_events = pd.read_csv(\"events.csv\")\n",
    "df_events = df_events.sort_values(by=['timestamp'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1430622004384</td>\n",
       "      <td>693516</td>\n",
       "      <td>addtocart</td>\n",
       "      <td>297662</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1430622011289</td>\n",
       "      <td>829044</td>\n",
       "      <td>view</td>\n",
       "      <td>60987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1430622013048</td>\n",
       "      <td>652699</td>\n",
       "      <td>view</td>\n",
       "      <td>252860</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1430622024154</td>\n",
       "      <td>1125936</td>\n",
       "      <td>view</td>\n",
       "      <td>33661</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1430622026228</td>\n",
       "      <td>693516</td>\n",
       "      <td>view</td>\n",
       "      <td>297662</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  visitorid      event  itemid  transactionid\n",
       "0  1430622004384     693516  addtocart  297662            NaN\n",
       "1  1430622011289     829044       view   60987            NaN\n",
       "2  1430622013048     652699       view  252860            NaN\n",
       "3  1430622024154    1125936       view   33661            NaN\n",
       "4  1430622026228     693516       view  297662            NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2756101 entries, 0 to 2756100\n",
      "Data columns (total 5 columns):\n",
      "timestamp        int64\n",
      "visitorid        int64\n",
      "event            object\n",
      "itemid           int64\n",
      "transactionid    float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 105.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of users: 1407580\n",
      "Original number of items: 235061\n",
      "Original number of interactions: 2756101\n",
      "Original sparsity: 0.000833 %\n"
     ]
    }
   ],
   "source": [
    "qty_all_users_original = len(df_events.visitorid.unique())\n",
    "qty_all_items_original = len(df_events.itemid.unique())\n",
    "qty_all_interactions_original = len(df_events)\n",
    "sparsity_original = qty_all_interactions_original/(qty_all_users_original*qty_all_items_original)\n",
    "\n",
    "print('Original number of users:', qty_all_users_original)\n",
    "print('Original number of items:', qty_all_items_original)\n",
    "print('Original number of interactions:', qty_all_interactions_original)\n",
    "print('Original sparsity:', round(sparsity_original*100,6), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Events types “view”, “addtocart”, “transaction” are the implicit customer feedback.\n",
    "# They cannot be considered as rating (explicit feedback).\n",
    "# This information is implicit feedback and lightFM library was designed to deal with it.\n",
    "# Transform events from categorical to numerical format for further processing.\n",
    "\n",
    "weight_view = 1\n",
    "weight_addtocart = 2\n",
    "weight_transaction = 3\n",
    "\n",
    "df_events.event.replace(to_replace=dict(\n",
    "    view=weight_view, addtocart=weight_addtocart, transaction=weight_transaction), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the events replaced with corresponding weights.\n",
    "df_events.event.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1430622004384</td>\n",
       "      <td>693516</td>\n",
       "      <td>2</td>\n",
       "      <td>297662</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1430622011289</td>\n",
       "      <td>829044</td>\n",
       "      <td>1</td>\n",
       "      <td>60987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1430622013048</td>\n",
       "      <td>652699</td>\n",
       "      <td>1</td>\n",
       "      <td>252860</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1430622024154</td>\n",
       "      <td>1125936</td>\n",
       "      <td>1</td>\n",
       "      <td>33661</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1430622026228</td>\n",
       "      <td>693516</td>\n",
       "      <td>1</td>\n",
       "      <td>297662</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  visitorid  event  itemid  transactionid\n",
       "0  1430622004384     693516      2  297662            NaN\n",
       "1  1430622011289     829044      1   60987            NaN\n",
       "2  1430622013048     652699      1  252860            NaN\n",
       "3  1430622024154    1125936      1   33661            NaN\n",
       "4  1430622026228     693516      1  297662            NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The user may have interacted with item multiple times which is now stored in dataframe.\n",
    "# For the purpose of recommendation we're interested in the highest level of user interest to the item.\n",
    "# Therefore, the data can be further cleaned.\n",
    "\n",
    "df_events = df_events.sort_values('event').drop_duplicates(\n",
    "    subset=['visitorid', 'itemid'], \n",
    "    keep='last').sort_values(by=['timestamp'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2145179 entries, 0 to 2145178\n",
      "Data columns (total 5 columns):\n",
      "timestamp        int64\n",
      "visitorid        int64\n",
      "event            int64\n",
      "itemid           int64\n",
      "transactionid    float64\n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 81.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff3905eae90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEGCAYAAABVSfMhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZk0lEQVR4nO3df6zd9X3f8eerdkhpG4opl4xhUtPUjUpY6wSLWEOtstCCQV1NM0hBbXBTNicZdIlWZSHdNDLSSOmiNCpVSkWFix2l/BgkxavIqEVZo7Yh4ZIwfibzDU3DLR44mBAy2mSm7/1xPrccX8794Rvu54Dv8yF9db7n/f18Pt/P0ZX10vf7/ficVBWSJPXyPeOegCRpZTF4JEldGTySpK4MHklSVwaPJKmr1eOewIvdscceW+vWrRv3NCTpJeXuu+/+elVNjDpm8Cxg3bp1TE5OjnsakvSSkuRv5jrmrTZJUlcGjySpK4NHktSVwSNJ6srgkSR1ZfBIkroyeCRJXRk8kqSuDB5JUld+c8EL6NT37Bz3FFaEuz980binIOm74BWPJKkrg0eS1JXBI0nqyuCRJHW1bMGT5MQkdyR5KMkDSd7V6sck2Z1kT3td0+pJcmWSqST3Jnn90FhbW/s9SbYO1U9Ncl/rc2WSLPUckqQ+lvOK5wDw61X148Am4JIkJwOXAbdX1Xrg9vYe4Gxgfdu2AVfBIESAy4E3AKcBl88ESWuzbajf5lY/pHNIkvpZtuCpqr1V9YW2/zTwEHACsAXY0ZrtAM5t+1uAnTVwJ3B0kuOBs4DdVbW/qp4EdgOb27GjquqzVVXAzlljHco5JEmddHnGk2Qd8Drgc8Arq2ovDMIJOK41OwF4ZKjbdKvNV58eUWcJ55g9321JJpNM7tu371A+qiRpAcsePEl+ALgZeHdVfXO+piNqtYT6vNNZTJ+qurqqNlbVxomJkT8ZLklaomUNniQvYxA6n6iqT7byYzO3t9rr460+DZw41H0t8OgC9bUj6ks5hySpk+Vc1RbgGuChqvrtoUO7gJmVaVuBW4bqF7WVZ5uAp9ptstuAM5OsaYsKzgRua8eeTrKpneuiWWMdyjkkSZ0s53e1nQ68FbgvyT2t9hvAh4Abk1wMfA04vx27FTgHmAKeAd4GUFX7k3wAuKu1u6Kq9rf9dwLXAkcCn24bh3oOSVI/yxY8VfUXjH6mAnDGiPYFXDLHWNuB7SPqk8ApI+pPHOo5JEl9+M0FkqSuDB5JUlcGjySpK4NHktSVwSNJ6srgkSR1ZfBIkroyeCRJXRk8kqSuDB5JUlcGjySpK4NHktSVwSNJ6srgkSR1ZfBIkrpazl8g3Z7k8ST3D9VuSHJP27468wNxSdYl+buhY78/1OfUJPclmUpyZfu1UZIck2R3kj3tdU2rp7WbSnJvktcPjbW1td+TZCuSpO6W84rnWmDzcKGqfrGqNlTVBuBm4JNDh78yc6yq3jFUvwrYBqxv28yYlwG3V9V64Pb2HuDsobbbWn+SHANcDrwBOA24fCasJEn9LFvwVNVngP2jjrWrlrcA1803RpLjgaOq6rPt10N3Aue2w1uAHW1/x6z6zhq4Ezi6jXMWsLuq9lfVk8BuZgWjJGn5jesZz08Bj1XVnqHaSUm+mOTPk/xUq50ATA+1mW41gFdW1V6A9nrcUJ9HRvSZqy5J6mj1mM57IQdf7ewFXlVVTyQ5FfjjJK8FMqJvLTD2XH0WPVaSbQxu0/GqV71qgdNJkg5F9yueJKuBNwM3zNSq6ttV9UTbvxv4CvBjDK5K1g51Xws82vYfa7fQZm7JPd7q08CJI/rMVX+eqrq6qjZW1caJiYmlfExJ0hzGcavtZ4AvVdU/3kJLMpFkVdv/EQYLAx5ut9CeTrKpPRe6CLilddsFzKxM2zqrflFb3bYJeKqNcxtwZpI1bVHBma0mSepo2W61JbkOeCNwbJJp4PKquga4gOcvKvhp4IokB4BngXdU1czChHcyWCF3JPDptgF8CLgxycXA14DzW/1W4BxgCngGeBtAVe1P8gHgrtbuiqFzSJI6WbbgqaoL56j/yojazQyWV49qPwmcMqL+BHDGiHoBl8wx1nZg+3zzliQtL7+5QJLUlcEjSerK4JEkdWXwSJK6MngkSV0ZPJKkrgweSVJXBo8kqSuDR5LUlcEjSerK4JEkdWXwSJK6MngkSV0ZPJKkrgweSVJXBo8kqatlC54k25M8nuT+odr7k/xtknvads7QsfclmUry5SRnDdU3t9pUksuG6icl+VySPUluSHJEq7+8vZ9qx9ctdA5JUj/LecVzLbB5RP2jVbWhbbcCJDmZwU9iv7b1+b0kq5KsAj4GnA2cDFzY2gL8VhtrPfAkcHGrXww8WVU/Cny0tZvzHC/wZ5YkLWDZgqeqPgPsX2TzLcD1VfXtqvprYAo4rW1TVfVwVX0HuB7YkiTAm4CbWv8dwLlDY+1o+zcBZ7T2c51DktTROJ7xXJrk3nYrbk2rnQA8MtRmutXmqv8Q8I2qOjCrftBY7fhTrf1cY0mSOuodPFcBrwY2AHuBj7R6RrStJdSXMtbzJNmWZDLJ5L59+0Y1kSQtUdfgqarHqurZqvoH4A947lbXNHDiUNO1wKPz1L8OHJ1k9az6QWO14z/I4JbfXGONmufVVbWxqjZOTEws5aNKkubQNXiSHD/09heAmRVvu4AL2oq0k4D1wOeBu4D1bQXbEQwWB+yqqgLuAM5r/bcCtwyNtbXtnwf8WWs/1zkkSR2tXrjJ0iS5DngjcGySaeBy4I1JNjC4xfVV4O0AVfVAkhuBB4EDwCVV9Wwb51LgNmAVsL2qHmineC9wfZLfBL4IXNPq1wAfTzLF4ErngoXOIUnqJ4OLAc1l48aNNTk5uai2p75n5zLPRgB3f/iicU9B0gKS3F1VG0cd85sLJEldGTySpK4MHklSVwaPJKkrg0eS1JXBI0nqyuCRJHVl8EiSujJ4JEldGTySpK4MHklSVwaPJKkrg0eS1JXBI0nqyuCRJHVl8EiSulq24EmyPcnjSe4fqn04yZeS3JvkU0mObvV1Sf4uyT1t+/2hPqcmuS/JVJIrk6TVj0myO8me9rqm1dPaTbXzvH5orK2t/Z4kW5EkdbecVzzXAptn1XYDp1TVTwD/G3jf0LGvVNWGtr1jqH4VsA1Y37aZMS8Dbq+q9cDt7T3A2UNtt7X+JDmGwc9vvwE4Dbh8JqwkSf0sW/BU1WeA/bNqf1pVB9rbO4G1842R5HjgqKr6bA1+o3sncG47vAXY0fZ3zKrvrIE7gaPbOGcBu6tqf1U9ySAEZwejJGmZjfMZz68Cnx56f1KSLyb58yQ/1WonANNDbaZbDeCVVbUXoL0eN9TnkRF95qo/T5JtSSaTTO7bt+/QP5kkaU5jCZ4k/xE4AHyilfYCr6qq1wH/HvijJEcBGdG9Fhp+jj6LHquqrq6qjVW1cWJiYoHTSZIORffgaQ/1fw74pXb7jKr6dlU90fbvBr4C/BiDq5Lh23FrgUfb/mPtFtrMLbnHW30aOHFEn7nqkqSOugZPks3Ae4Gfr6pnhuoTSVa1/R9hsDDg4XYL7ekkm9pqtouAW1q3XcDMyrSts+oXtdVtm4Cn2ji3AWcmWdMWFZzZapKkjlYv18BJrgPeCBybZJrBirL3AS8HdrdV0Xe2FWw/DVyR5ADwLPCOqppZmPBOBivkjmTwTGjmudCHgBuTXAx8DTi/1W8FzgGmgGeAtwFU1f4kHwDuau2uGDqHJKmTRQVPktur6oyFasOq6sIR5WvmaHszcPMcxyaBU0bUnwCed/52++6SOcbaDmyfa86SpOU3b/Ak+V7g+xhctazhuQf0RwH/dJnnJkk6DC10xfN24N0MQuZunguebwIfW8Z5SZIOU/MGT1X9DvA7SX6tqn6305wkSYexRT3jqarfTfLPgXXDfapq5zLNS5J0mFrs4oKPA68G7mGw6gwG//nS4JEkHZLFLqfeCJw88x8+JUlaqsX+B9L7gX+ynBORJK0Mi73iORZ4MMnngW/PFKvq55dlVpKkw9Zig+f9yzkJSdLKsdhVbX++3BORJK0Mi13V9jTP/YTAEcDLgP9bVUct18QkSYenxV7xvGL4fZJzGfx8tCRJh2RJP4tQVX8MvOkFnoskaQVY7K22Nw+9/R4G/6/H/9MjSTpki13V9i+H9g8AXwW2vOCzkSQd9hb7jOdtyz0RSdLKsKhnPEnWJvlUkseTPJbk5iRrF9Fve+tz/1DtmCS7k+xpr2taPUmuTDKV5N4krx/qs7W135Nk61D91CT3tT5Xtp/HXtI5JEl9LHZxwR8Cuxj8Ls8JwH9vtYVcC2yeVbsMuL2q1gO3t/cAZwPr27YNuAoGIcLgZ7PfwGAl3eUzQdLabBvqt3kp55Ak9bPY4Jmoqj+sqgNtuxaYWKhTVX0G2D+rvAXY0fZ3AOcO1XfWwJ3A0UmOB84CdlfV/qp6EtgNbG7Hjqqqz7YvL905a6xDOYckqZPFBs/Xk/xyklVt+2XgiSWe85VVtRegvR7X6icAjwy1m261+erTI+pLOcdBkmxLMplkct++fYf8ASVJc1ts8Pwq8Bbg/wB7gfOAF3rBQUbUagn1pZzj4ELV1VW1sao2TkwseGEnSToEiw2eDwBbq2qiqo5jEETvX+I5H5u5vdVeH2/1aeDEoXZrgUcXqK8dUV/KOSRJnSw2eH6iPV8BoKr2A69b4jl3ATMr07YCtwzVL2orzzYBT7XbZLcBZyZZ0xYVnAnc1o49nWRTW8120ayxDuUckqROFvsfSL8nyZqZ8GkrzRbsm+Q64I3AsUmmGaxO+xBwY5KLga8B57fmtwLnAFPAM7RbeVW1P8kHgLtauyta8AG8k8HKuSOBT7eNQz2HJKmfxQbPR4C/SnITg2cibwE+uFCnqrpwjkNnjGhbwCVzjLMd2D6iPgmcMqL+xKGeQ5LUx2K/uWBnkkkGXwwa4M1V9eCyzkySdFha7BUPLWgMG0nSd2VJP4sgSdJSGTySpK4MHklSVwaPJKkrg0eS1JXBI0nqyuCRJHVl8EiSujJ4JEldGTySpK4MHklSVwaPJKkrg0eS1JXBI0nqqnvwJHlNknuGtm8meXeS9yf526H6OUN93pdkKsmXk5w1VN/calNJLhuqn5Tkc0n2JLkhyRGt/vL2fqodX9fzs0uSxhA8VfXlqtpQVRuAUxn8BPWn2uGPzhyrqlsBkpwMXAC8FtgM/F6SVUlWAR8DzgZOBi5sbQF+q421HngSuLjVLwaerKofBT7a2kmSOhr3rbYzgK9U1d/M02YLcH1Vfbuq/hqYAk5r21RVPVxV3wGuB7YkCYNfSr2p9d8BnDs01o62fxNwRmsvSepk3MFzAXDd0PtLk9ybZHuSNa12AvDIUJvpVpur/kPAN6rqwKz6QWO140+19gdJsi3JZJLJffv2fTefT5I0y9iCpz13+Xngv7XSVcCrgQ3AXuAjM01HdK8l1Ocb6+BC1dVVtbGqNk5MTMz5GSRJh26cVzxnA1+oqscAquqxqnq2qv4B+AMGt9JgcMVy4lC/tcCj89S/DhydZPWs+kFjteM/COx/gT+XJGke4wyeCxm6zZbk+KFjvwDc3/Z3ARe0FWknAeuBzwN3AevbCrYjGNy221VVBdwBnNf6bwVuGRpra9s/D/iz1l6S1MnqhZu88JJ8H/CzwNuHyv81yQYGt76+OnOsqh5IciPwIHAAuKSqnm3jXArcBqwCtlfVA22s9wLXJ/lN4IvANa1+DfDxJFMMrnQuWLYPKUkaaSzBU1XPMOuhflW9dZ72HwQ+OKJ+K3DriPrDPHerbrj+98D5S5iyJOkFMu5VbZKkFcbgkSR1ZfBIkroyeCRJXRk8kqSuDB5JUlcGjySpK4NHktSVwSNJ6srgkSR1ZfBIkroyeCRJXRk8kqSuDB5JUlcGjySpK4NHktTV2IInyVeT3JfkniSTrXZMkt1J9rTXNa2eJFcmmUpyb5LXD42ztbXfk2TrUP3UNv5U65v5ziFJ6mPcVzz/oqo2VNXG9v4y4PaqWg/c3t4DnA2sb9s24CoYhAhwOfAGBr84evlQkFzV2s7027zAOSRJHYw7eGbbAuxo+zuAc4fqO2vgTuDoJMcDZwG7q2p/VT0J7AY2t2NHVdVnq6qAnbPGGnUOSVIH4wyeAv40yd1JtrXaK6tqL0B7Pa7VTwAeGeo73Wrz1adH1Oc7xz9Ksi3JZJLJffv2fRcfUZI02+oxnvv0qno0yXHA7iRfmqdtRtRqCfVFqaqrgasBNm7cuOh+kqSFje2Kp6oeba+PA59i8IzmsXabjPb6eGs+DZw41H0t8OgC9bUj6sxzDklSB2MJniTfn+QVM/vAmcD9wC5gZmXaVuCWtr8LuKitbtsEPNVuk90GnJlkTVtUcCZwWzv2dJJNbTXbRbPGGnUOSVIH47rV9krgU22F82rgj6rqfyS5C7gxycXA14DzW/tbgXOAKeAZ4G0AVbU/yQeAu1q7K6pqf9t/J3AtcCTw6bYBfGiOc0iSOhhL8FTVw8BPjqg/AZwxol7AJXOMtR3YPqI+CZyy2HNIkvp4sS2nliQd5gweSVJXBo8kqSuDR5LUlcEjSerK4JEkdWXwSJK6MngkSV0ZPJKkrgweSVJXBo8kqSuDR5LUlcEjSerK4JEkdWXwSJK6MngkSV11D54kJya5I8lDSR5I8q5Wf3+Sv01yT9vOGerzviRTSb6c5Kyh+uZWm0py2VD9pCSfS7InyQ1Jjmj1l7f3U+34un6fXJIE47niOQD8elX9OLAJuCTJye3YR6tqQ9tuBWjHLgBeC2wGfi/JqiSrgI8BZwMnAxcOjfNbbaz1wJPAxa1+MfBkVf0o8NHWTpLUUffgqaq9VfWFtv808BBwwjxdtgDXV9W3q+qvgSngtLZNVdXDVfUd4HpgS5IAbwJuav13AOcOjbWj7d8EnNHaS5I6Gesznnar63XA51rp0iT3JtmeZE2rnQA8MtRtutXmqv8Q8I2qOjCrftBY7fhTrf3seW1LMplkct++fd/VZ5QkHWxswZPkB4CbgXdX1TeBq4BXAxuAvcBHZpqO6F5LqM831sGFqquramNVbZyYmJj3c0iSDs1YgifJyxiEzieq6pMAVfVYVT1bVf8A/AGDW2kwuGI5caj7WuDReepfB45OsnpW/aCx2vEfBPa/sJ9OkjSfcaxqC3AN8FBV/fZQ/fihZr8A3N/2dwEXtBVpJwHrgc8DdwHr2wq2IxgsQNhVVQXcAZzX+m8Fbhkaa2vbPw/4s9ZektTJ6oWbvOBOB94K3Jfknlb7DQar0jYwuPX1VeDtAFX1QJIbgQcZrIi7pKqeBUhyKXAbsArYXlUPtPHeC1yf5DeBLzIIOtrrx5NMMbjSuWA5P6gk6fm6B09V/QWjn7XcOk+fDwIfHFG/dVS/qnqY527VDdf/Hjj/UOYrSXph+c0FkqSuDB5JUlcGjySpK4NHktSVwSNJ6srgkSR1ZfBIkroyeCRJXRk8kqSuDB5JUlcGjySpK4NHktSVwSNJ6srgkSR1ZfBIkroaxw/BSS9KX7vin417Coe9V/3n+8Y9Bb0IrMgrniSbk3w5yVSSy8Y9H0laSVbcFU+SVcDHgJ8FpoG7kuyqqgfHOzNJ343Tf/f0cU/hsPeXv/aXL8g4K/GK5zRgqqoerqrvANcDW8Y8J0laMVJV455DV0nOAzZX1b9u798KvKGqLh1qsw3Y1t6+Bvhy94n2cyzw9XFPQkvm3++l63D/2/1wVU2MOrDibrUBGVE7KH2r6mrg6j7TGa8kk1W1cdzz0NL493vpWsl/u5V4q20aOHHo/Vrg0THNRZJWnJUYPHcB65OclOQI4AJg15jnJEkrxoq71VZVB5JcCtwGrAK2V9UDY57WOK2IW4qHMf9+L10r9m+34hYXSJLGayXeapMkjZHBI0nqyuBZoZJsT/J4kvvHPRcdmiQnJrkjyUNJHkjyrnHPSYuX5HuTfD7J/2p/v/8y7jn15jOeFSrJTwPfAnZW1Snjno8WL8nxwPFV9YUkrwDuBs71a59eGpIE+P6q+laSlwF/Abyrqu4c89S68YpnhaqqzwD7xz0PHbqq2ltVX2j7TwMPASeMd1ZarBr4Vnv7sratqCsAg0d6CUuyDngd8LnxzkSHIsmqJPcAjwO7q2pF/f0MHuklKskPADcD766qb457Plq8qnq2qjYw+OaU05KsqNvdBo/0EtSeDdwMfKKqPjnu+WhpquobwP8ENo95Kl0ZPNJLTHs4fQ3wUFX99rjno0OTZCLJ0W3/SOBngC+Nd1Z9GTwrVJLrgM8Cr0kyneTicc9Ji3Y68FbgTUnuads5456UFu144I4k9zL47sjdVfUnY55TVy6nliR15RWPJKkrg0eS1JXBI0nqyuCRJHVl8EiSujJ4pBUgyblJTh73PCQweKSV4lzA4NGLgv+PR3qRSPLLwL8DjmDwpZ/3Aj9cVf+hHf8V4NSq+rURbf9tVT2b5FvA7wA/B/wdsAV4NfAnwFNt+1dV9ZWen00a5hWP9CKQ5MeBXwROb18e+SyD30t681CzXwRumKPtL7U23w/cWVU/CXwG+DdV9VfALuA9VbXB0NG4rR73BCQBcAZwKnDX4KvYOJLBV+Y/nGQTsAd4DfCXwCVztAX4DoOrGxj8QNzPdpq/tGgGj/TiEGBHVb3voOLgO/TewuBLJD9VVdW+JPR5bZv/V8/dP38W/43rRchbbdKLw+3AeUmOA0hyTJIfBj7JYGHAhcANC7Sdz9PAK5Zl5tIhMnikF4GqehD4T8Cftm8t3g0cX1VPAg8yWGTw+fnaLnCK64H3JPliklcv1+eQFsNVbZKkrrzikSR1ZfBIkroyeCRJXRk8kqSuDB5JUlcGjySpK4NHktTV/wcOQNo0CUG/WQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View on the ratio between different types of events.\n",
    "sns.countplot(x='event', data=df_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitorid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           activity_count\n",
       "visitorid                \n",
       "0                       3\n",
       "1                       1\n",
       "2                       4\n",
       "3                       1\n",
       "4                       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count activities by user.\n",
    "users_activity = df_events.groupby('visitorid').visitorid.count().to_frame(name='activity_count')\n",
    "users_activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitorid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1150086</td>\n",
       "      <td>3814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530559</td>\n",
       "      <td>2209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892013</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895999</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152963</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371606</td>\n",
       "      <td>1399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163561</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79627</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286616</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>684514</td>\n",
       "      <td>1187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           activity_count\n",
       "visitorid                \n",
       "1150086              3814\n",
       "530559               2209\n",
       "892013               1738\n",
       "895999               1641\n",
       "152963               1622\n",
       "371606               1399\n",
       "163561               1314\n",
       "79627                1257\n",
       "286616               1230\n",
       "684514               1187"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View on the most active users\n",
    "users_activity.loc[users_activity['activity_count'] > 1000].sort_values(\n",
    "    by='activity_count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>628771</td>\n",
       "      <td>1434034517389</td>\n",
       "      <td>1150086</td>\n",
       "      <td>1</td>\n",
       "      <td>133542</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629008</td>\n",
       "      <td>1434035735608</td>\n",
       "      <td>1150086</td>\n",
       "      <td>1</td>\n",
       "      <td>167873</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629054</td>\n",
       "      <td>1434036006651</td>\n",
       "      <td>1150086</td>\n",
       "      <td>1</td>\n",
       "      <td>231726</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629104</td>\n",
       "      <td>1434036288806</td>\n",
       "      <td>1150086</td>\n",
       "      <td>1</td>\n",
       "      <td>427777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629170</td>\n",
       "      <td>1434036525614</td>\n",
       "      <td>1150086</td>\n",
       "      <td>3</td>\n",
       "      <td>398115</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629208</td>\n",
       "      <td>1434036727711</td>\n",
       "      <td>1150086</td>\n",
       "      <td>1</td>\n",
       "      <td>203425</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629246</td>\n",
       "      <td>1434036891672</td>\n",
       "      <td>1150086</td>\n",
       "      <td>1</td>\n",
       "      <td>458489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629369</td>\n",
       "      <td>1434037348016</td>\n",
       "      <td>1150086</td>\n",
       "      <td>3</td>\n",
       "      <td>375955</td>\n",
       "      <td>6495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629421</td>\n",
       "      <td>1434037596453</td>\n",
       "      <td>1150086</td>\n",
       "      <td>3</td>\n",
       "      <td>357133</td>\n",
       "      <td>5235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629625</td>\n",
       "      <td>1434038553908</td>\n",
       "      <td>1150086</td>\n",
       "      <td>2</td>\n",
       "      <td>368244</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  visitorid  event  itemid  transactionid\n",
       "628771  1434034517389    1150086      1  133542            NaN\n",
       "629008  1434035735608    1150086      1  167873            NaN\n",
       "629054  1434036006651    1150086      1  231726            NaN\n",
       "629104  1434036288806    1150086      1  427777            NaN\n",
       "629170  1434036525614    1150086      3  398115         7510.0\n",
       "629208  1434036727711    1150086      1  203425            NaN\n",
       "629246  1434036891672    1150086      1  458489            NaN\n",
       "629369  1434037348016    1150086      3  375955         6495.0\n",
       "629421  1434037596453    1150086      3  357133         5235.0\n",
       "629625  1434038553908    1150086      2  368244            NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.loc[df_events['visitorid'] == 1150086].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the hypothesys: the more interactions the user had, the more likely addtocart/purchase was made.\n",
    "# Based on this hypothesys the users can be divided into two groups.\n",
    "\n",
    "# First group is 'low activity' users - this group is mostly browsing and not making many purchases.\n",
    "# The ratio of addtocart/purchase is low so it is harder to understand what they really like.\n",
    "# Therefore, all types of interactions (view/addtocart/purchase) can be counted as positive.\n",
    "# This will lead at least to improvement of customer experience and users are more likely to find the needed item.\n",
    "# For the purposes of this project 'low activity' group will be left aside as the goal is basket value, not UX.\n",
    "\n",
    "# Second group is 'high activity' users - this group has higher ratio of purchases.\n",
    "# Therefore, addtocart/purchase can be considered as positive interactions and predictions be made on them.\n",
    "# View interactions are not considered since the user has not proceeded so this means there's low interest.\n",
    "# This will allow to get rid of noise.\n",
    "# For the purposes of this project 'high activity' group will be used.\n",
    "\n",
    "# Overall, using this split resolves several issues:\n",
    "# 1. The low activity users represent the noise which will affect the model performance.\n",
    "# 2. The size of dataframe used for the further steps will be significantly smaller saving computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop the function to see how the number of interactions impacts conversion.\n",
    "\n",
    "def activity_counter(data, max_interaction_threshold):\n",
    "    \n",
    "    df_events = data\n",
    "    users_activity = df_events.groupby('visitorid').visitorid.count().to_frame(name='activity_count')\n",
    "    count_aggregated = pd.DataFrame(columns = ['interaction_threshold', \n",
    "                                               'view', 'addtocart', 'purchase', \n",
    "                                               'conversion', \n",
    "                                               'total_interactions'])\n",
    "    \n",
    "    for interaction_threshold in range(max_interaction_threshold):\n",
    "        users_activity_low = users_activity.loc[users_activity['activity_count'] <= interaction_threshold]\n",
    "        users_to_remove = users_activity_low.index.tolist()\n",
    "        df_events = df_events[~df_events.visitorid.isin(users_to_remove)].reset_index(drop=True)\n",
    "        \n",
    "        count = df_events['event'].value_counts()\n",
    "        count_aggregated = count_aggregated.append({\n",
    "            'interaction_threshold': int(interaction_threshold), \n",
    "            'view': int(count[weight_view]), \n",
    "            'addtocart': int(count[weight_addtocart]), \n",
    "            'purchase': int(count[weight_transaction]), \n",
    "            'conversion': (count[weight_addtocart] + count[weight_transaction])/len(df_events),\n",
    "            'total_interactions': len(df_events)\n",
    "        }, \n",
    "            ignore_index=True)\n",
    "        \n",
    "    return(count_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run fuction.\n",
    "activities = activity_counter(df_events, 100)\n",
    "activities.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, (axis_1, axis_2) = plt.subplots(2)\n",
    "figure.suptitle('User activity visualization')\n",
    "\n",
    "axis_1.plot(activities['interaction_threshold'], activities['conversion'], 'r')\n",
    "axis_1.set_ylabel('Conversion')\n",
    "\n",
    "axis_2.plot(activities['interaction_threshold'], activities['total_interactions'], 'g')\n",
    "axis_2.plot(activities['interaction_threshold'], activities['total_interactions'], 'g')\n",
    "axis_2.set_ylabel('Total interactions')\n",
    "axis_2.set_xlabel('Interactions per user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot above shows that positive ratio improvement slows down significantly at 20 interactions threshold.\n",
    "# Plateau is at conversion rate ~0.1 (10%) which is good in comparison to eCommerce industry standard 3%.\n",
    "# It makes sense since the part of less active users was removed.\n",
    "\n",
    "# Hypothesis is now proved. \n",
    "\n",
    "# Split point to divide users into two groups:\n",
    "# 'low activity' users with 20 and less interactions.\n",
    "# 'high activity' users with more than 20 interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set interactions threshold and remove 'low activity' users.\n",
    "\n",
    "interaction_threshold = 20\n",
    "\n",
    "# Create list of users that need to be removed from events data.\n",
    "users_activity_low = users_activity.loc[users_activity['activity_count'] <= interaction_threshold]\n",
    "users_to_remove = users_activity_low.index.tolist()\n",
    "\n",
    "# Remove low activity users from dataframe.\n",
    "df_events = df_events[~df_events.visitorid.isin(users_to_remove)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select which types of interaction to be used: weight_view / weight_addtocart / weight_transaction.\n",
    "# View interactions are not considered since the user has not proceeded so this means there's low interest.\n",
    "\n",
    "df_events = df_events.loc[df_events['event'].isin(\n",
    "    [weight_addtocart, \n",
    "     weight_transaction])].reset_index(drop=True)\n",
    "\n",
    "df_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Final view on users and items participating in model training and testing. \n",
    "\n",
    "qty_all_users = len(df_events['visitorid'].unique())\n",
    "print('Original number of users:', qty_all_users_original)\n",
    "print('Cleaned dataset number of users: ', qty_all_users)\n",
    "print('Cleaned portion:', round(100*qty_all_users/qty_all_users_original,2), '%')\n",
    "print()\n",
    "\n",
    "qty_all_items = len(df_events['itemid'].unique())\n",
    "print('Original number of items:', qty_all_items_original)\n",
    "print('Cleaned dataset number of items: ', qty_all_items)\n",
    "print('Cleaned portion:', round(100*qty_all_items/qty_all_items_original,2), '%')\n",
    "print()\n",
    "\n",
    "qty_all_interactions = len(df_events)\n",
    "print('Original number of interactions:', qty_all_interactions_original)\n",
    "print('Cleaned dataset number of interactions: ', qty_all_interactions)\n",
    "print('Cleaned portion:', round(100*qty_all_interactions/qty_all_interactions_original,2), '%')\n",
    "print()\n",
    "\n",
    "sparsity = qty_all_interactions/(qty_all_users*qty_all_items)\n",
    "print('Original sparsity: ', round(sparsity_original*100,6), '%')\n",
    "print('Cleaned sparsity: ', round(100*sparsity,6), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Use timestamps for split which mimics the real-life case as the events are sorted in historical order.\n",
    "\n",
    "split_point = int(np.ceil(len(df_events)*0.8))  # Index of split point.\n",
    "split_point_time = int(df_events.loc[split_point]['timestamp'])  # Timestamp of split point.\n",
    "\n",
    "df_events_train = df_events.loc[0:split_point]\n",
    "df_events_test = df_events.loc[split_point+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactions data may depend on seasonality and specific eCommerce events.\n",
    "# In order to achieve the generalization, the train and test split will be done randomly.\n",
    "df_events_train, df_events_test = train_test_split(df_events, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=np.random.RandomState(2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset used for this project does not have any user informnation (features) available.\n",
    "# Therefore, on the evaluation phase there should be only those users model was trained on.\n",
    "# Otherwise the user cold start problem will be faced which will impact the evaluation results.\n",
    "\n",
    "df_events_test = df_events_test[(df_events_test['visitorid'].isin(df_events_train['visitorid'])) & \n",
    "                                (df_events_test['itemid'].isin(df_events_train['itemid']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_events_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Test set represents', round(100*len(df_events_test)/len(df_events_train),2),'% of Train set.')\n",
    "print('Total number of interactions participating in train:',len(df_events_train),'/ test: ', len(df_events_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming interactions data into the format acceptable by lightFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class of LightFM package has method build_interactions that allows to fill in the interactions matrix.\n",
    "# As the input for this method need to pass the list of tuples (visitorid, itemid, weight).\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train set interactions transformed.\n",
    "df_events_train_interactions = []\n",
    "for index, row in df_events_train.iterrows():\n",
    "    df_events_train_interactions.append((int(row['visitorid']), int(row['itemid']), int(row['event'])))\n",
    "    \n",
    "# Test set interactions transformed.\n",
    "df_events_test_interactions = []\n",
    "for index, row in df_events_test.iterrows():\n",
    "    df_events_test_interactions.append((int(row['visitorid']), int(row['itemid']), int(row['event'])))\n",
    "    \n",
    "print('Finished in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check original VS transformed length, should be equal.\n",
    "\n",
    "print('Check original VS transformed length TRAIN: ', \n",
    "     len(df_events_train),\n",
    "     '/',\n",
    "     len(df_events_train_interactions))\n",
    "\n",
    "print('Check original VS transformed length TEST: ', \n",
    "     len(df_events_test),\n",
    "     '/',\n",
    "     len(df_events_test_interactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Data Import and Cleaning - Item Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import Properties\n",
    "\n",
    "df_properties1 = pd.DataFrame(pd.read_csv(\"item_properties_part1.csv\"))\n",
    "df_properties2 = pd.DataFrame(pd.read_csv(\"item_properties_part2.csv\"))\n",
    "df_properties = pd.concat([df_properties1, df_properties2])\n",
    "\n",
    "# data to be sorted by timestamp to reflect the historical change log.\n",
    "df_properties = df_properties.sort_values(by=['timestamp'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "df_properties.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_properties.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties_len_orig = len(df_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# All the categories names and values are hashed excepting \"categoryid\" and \"available\".\n",
    "\n",
    "df_properties.loc[df_properties['itemid'] == 216269].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model is unable to process the historical log so there's a need to trim the properties data.\n",
    "# The latest properties data is considered to be the best to describe items assuming the ecommerce team was \n",
    "# constantly improving the catalogue.\n",
    "# This action should lead to decrease of the dataframe size.\n",
    "\n",
    "df_properties = df_properties.sort_values(by=['timestamp'], ascending=True).drop_duplicates(\n",
    "    subset=['itemid', 'property'], \n",
    "    keep='last').reset_index(drop=True)\n",
    "\n",
    "df_properties.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Additionally, we can get rid of the 'available' property completely.\n",
    "# It won't make sense to consider any value as fixed (in stock or not in stock) for trainig purposes.\n",
    "# In production this property can be used in real time to filter out unavailable items from prediction.\n",
    "\n",
    "df_properties = df_properties[~df_properties.property.isin(['available'])].reset_index(drop=True)\n",
    "\n",
    "df_properties.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the next step the items which are not present in the cleaned dataframe can also be removed.\n",
    "\n",
    "df_properties = df_properties[df_properties.itemid.isin(df_events['itemid'])].reset_index(drop=True)\n",
    "\n",
    "df_properties.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp column can also be removed as it is redundant.\n",
    "\n",
    "df_properties = df_properties.drop(['timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by itemid.\n",
    "\n",
    "df_properties = df_properties.sort_values(by=['itemid'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cleaned properties dataframe represents ',\n",
    "      round(100*len(df_properties)/df_properties_len_orig,2),\n",
    "     ' % of original dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qty_all_properties = len(df_properties['property'].unique())\n",
    "print('Cleaned dataset number of properties: ', qty_all_properties)\n",
    "print('Cleaned dataset number of properties values: ', len(df_properties))\n",
    "print()\n",
    "print('Cleaned dataset number of items: ', qty_all_items)\n",
    "print('Cleaned dataset number of users: ', qty_all_users)\n",
    "print('Cleaned dataset number of interactions: ', len(df_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_properties.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming item features data into the format acceptable by lightFM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The item features information should be passed to the lightFM model in a format of csr matrix.\n",
    "# This matrix must have mapping of all items related to the train/test process and \n",
    "# all features available in cleaned properties dataframe.\n",
    "# Then the matrix is to be filled in with the properties values.\n",
    "# LightFM model would be then capable to create a latent features vector for each item.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_properties.loc[df_properties['itemid'] == 15].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset class has the method build_item_features that allows to fill in the properties data using created mapping.\n",
    "# Add feature mapping to the existing dataset using fit_partial method.\n",
    "# Data needs to be transformed to the acceptable format.\n",
    "# https://github.com/lyst/lightfm/issues/393#issuecomment-438237971\n",
    "\n",
    "\n",
    "# Transform item features list to the format required by Dataset class:\n",
    "# ['property:value']\n",
    "item_features_mapping = []\n",
    "for index, row in df_properties.iterrows():\n",
    "    item_features_mapping.append(str(row['property']) + ':' + str(row['value']))\n",
    "    \n",
    "print('Properties mapping has:', len(item_features_mapping), 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the next step need to remove duplicates in this list.\n",
    "# So basically the feature mapping lenght is not equal to the number of features, \n",
    "# but is equal to the number of combinations ['property:value'] available in the dataframe.\n",
    "# There's no need to \"create\" all possible combinations mapping as this is redundant info.\n",
    "# Just need to create mapping for existing combinations.\n",
    "# Additionally, the LightFM package allows to add weight to this combination if needed.\n",
    "\n",
    "item_features_mapping = list( dict.fromkeys(item_features_mapping) )\n",
    "print('Properties mapping has:', len(item_features_mapping), 'unique records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform item features values to the format required by Dataset class:\n",
    "# [ (itemid_1, ['property_1:value_1', 'property_2:value_2']) ]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "item_features_values = []\n",
    "current_item = df_properties.itemid[0]\n",
    "current_item_features = []\n",
    "for index, row in df_properties.iterrows():\n",
    "    if row['itemid'] == current_item:\n",
    "        current_item_features.append(str(row['property']) + ':' + str(row['value']))\n",
    "    else:\n",
    "        item_features_values.append((current_item, current_item_features))\n",
    "        current_item = row['itemid']\n",
    "        current_item_features = [str(row['property']) + ':' + str(row['value'])]\n",
    "item_features_values.append((current_item, current_item_features))\n",
    "\n",
    "print('Finished in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Create LightFM dataset mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation purposes (auc_score) dimensionality of train/test interaction matrices should be the same.\n",
    "# In order to achieve this, need to create mapping for all users and all items.\n",
    "# Then separately for train and test - the interactions will be filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping for users, items and item features.\n",
    "\n",
    "# The fit method of class Dataset takes the list of all the visitors and items.\n",
    "# The implementation allows to ignore duplicates.\n",
    "\n",
    "# Train set mapping.\n",
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    users = (x for x in df_events['visitorid']),\n",
    "    items = (x for x in df_events['itemid']), \n",
    "    user_features=None, \n",
    "    item_features=item_features_mapping\n",
    ")\n",
    "\n",
    "dataset_train = dataset\n",
    "dataset_test = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate LightFM dataset with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Populate interactions matrix for train and test sets.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "(interactions_train, weights_train) = dataset_train.build_interactions(df_events_train_interactions)\n",
    "(interactions_test, weights_test) = dataset_test.build_interactions(df_events_test_interactions)\n",
    "\n",
    "\n",
    "# Choose whether interactions or weights are to be used at next stages.\n",
    "\n",
    "train = interactions_train\n",
    "test = interactions_test\n",
    "\n",
    "print('Finished in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Populate item features matrix with values.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "item_features = dataset.build_item_features(item_features_values)\n",
    "\n",
    "print('Finished in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset class cross-check.')\n",
    "print()\n",
    "\n",
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('All users expected:', qty_all_users)\n",
    "print('Actual number of users:', num_users)\n",
    "print()\n",
    "print('All items expected:', qty_all_items)\n",
    "print('Actual number of items:', num_items)\n",
    "print()\n",
    "\n",
    "print('Item features matrix is expected to be of size: (', qty_all_items, ',', \n",
    "      qty_all_items+len(item_features_mapping), ')')\n",
    "# Reason for this size is that there's a space for latent vector representation of each item plus all features.\n",
    "print('Actual size is:', dataset.item_features_shape())\n",
    "print()\n",
    "\n",
    "print('Item features matrix number of values is expected to be:', len(df_properties)+qty_all_items)\n",
    "# Reason for this size is that there's a space for latent vector representation of each item plus all features.\n",
    "print('Actual number of values is:', item_features.getnnz())\n",
    "print()\n",
    "\n",
    "print('Interactions matrix is expected to be of the size: (', qty_all_users, ',', qty_all_items, ')')\n",
    "print('Actual size is:', dataset.interactions_shape())\n",
    "print()\n",
    "\n",
    "print('Interactions matrix number of values is expected to be:', len(df_events_train) + len(df_events_test))\n",
    "print('Actual number of values is:', train.getnnz() + test.getnnz())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM hybrid model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model with item features. This will mean hybrid predictions.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model_hybrid = LightFM(no_components=100, loss='warp', random_state=2020)\n",
    "\n",
    "model_hybrid.fit(train, \n",
    "                 item_features=item_features, \n",
    "                 epochs=100, \n",
    "                 num_threads=4)\n",
    "\n",
    "print('Model trained in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation (auc_score, precision_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the recommendation engine is a ranking problem, AUC ROC and Precision at K will be used.\n",
    "# Both of them are measuring the ranking quality.\n",
    "# Set parameter \"k\" value to check precision at \"k\"\n",
    "\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_auc = auc_score(model_hybrid, \n",
    "                      train, \n",
    "                      item_features=item_features, \n",
    "                      num_threads=4).mean()\n",
    "\n",
    "print('Train AUC score: ', train_auc)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train interactions fill be also passed to avoid model re-recommending items to users.\n",
    "test_auc = auc_score(model_hybrid,\n",
    "                     test, \n",
    "                     item_features=item_features, \n",
    "                     train_interactions = train, \n",
    "                     num_threads=4).mean()\n",
    "\n",
    "print('Test AUC score: ', test_auc)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_precision = precision_at_k(model_hybrid, \n",
    "                                 train,\n",
    "                                 item_features=item_features, \n",
    "                                 num_threads=4, \n",
    "                                 k=k).mean()\n",
    "\n",
    "print('Train precision at k: ', train_precision)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_precision = precision_at_k(model_hybrid, \n",
    "                                test, \n",
    "                                item_features=item_features, \n",
    "                                train_interactions = train, \n",
    "                                num_threads=4, \n",
    "                                k=k).mean()\n",
    "\n",
    "print('Test precision at k: ', test_precision)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_vis_auc(train, test, item_features, epochs):\n",
    "    \n",
    "    stats = pd.DataFrame(columns = ['epochs', 'train_auc', 'test_auc', 'runtime_min'])\n",
    "    model_hybrid = LightFM(no_components=100, loss='warp', random_state=2020)\n",
    "    \n",
    "    total_runtime_min = 0\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        model_hybrid.fit(train, \n",
    "                     item_features=item_features, \n",
    "                     epochs=epoch, \n",
    "                     num_threads=4)\n",
    "        \n",
    "        train_auc = auc_score(model_hybrid, \n",
    "                      train, \n",
    "                      item_features=item_features, \n",
    "                      num_threads=4).mean()\n",
    "\n",
    "        test_auc = auc_score(model_hybrid,\n",
    "                     test, \n",
    "                     item_features=item_features, \n",
    "                     train_interactions = train, \n",
    "                     num_threads=4).mean()\n",
    "\n",
    "        runtime_min = round((time.time()-start_time)/60, 6)        \n",
    "        total_runtime_min += runtime_min\n",
    "        \n",
    "        stats = stats.append({\n",
    "            'epochs': int(epoch), \n",
    "            'train_auc': float(train_auc), \n",
    "            'test_auc': float(test_auc),\n",
    "            'runtime_min': float(runtime_min)},\n",
    "            ignore_index=True)\n",
    "        \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    figure, axis = plt.subplots()\n",
    "    figure.suptitle('Learning progress: AUC')\n",
    "    axis.plot(stats['epochs'], stats['train_auc'], label='train')\n",
    "    axis.plot(stats['epochs'], stats['test_auc'], label='test')\n",
    "    axis.set_xlabel('Epochs')\n",
    "    axis.set_ylabel('AUC score')\n",
    "    axis.legend()\n",
    "    \n",
    "    return(figure, stats, total_runtime_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_vis_auc_output = learning_vis_auc(train, test, item_features, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_vis_auc_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_vis_auc_output[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_vis_precision(train, test, item_features, k, epochs):\n",
    "    \n",
    "    stats = pd.DataFrame(columns = ['epochs', 'train_precision', 'test_precision', '@k' 'runtime_min'])\n",
    "    model_hybrid = LightFM(no_components=100, loss='warp', random_state=2020)\n",
    "    \n",
    "    total_runtime_min = 0\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        model_hybrid.fit(train, \n",
    "                     item_features=item_features, \n",
    "                     epochs=epoch, \n",
    "                     num_threads=4)\n",
    "        \n",
    "        train_precision = precision_at_k(model_hybrid, \n",
    "                                 train,\n",
    "                                 item_features=item_features, \n",
    "                                 num_threads=4, \n",
    "                                 k=k).mean()\n",
    "\n",
    "        test_precision = precision_at_k(model_hybrid, \n",
    "                                 test,\n",
    "                                 item_features=item_features,\n",
    "                                 train_interactions=train, \n",
    "                                 num_threads=4, \n",
    "                                 k=k).mean()\n",
    "\n",
    "        runtime_min = round((time.time()-start_time)/60, 6)\n",
    "        total_runtime_min += runtime_min\n",
    "        \n",
    "        stats = stats.append({\n",
    "            'epochs': int(epoch), \n",
    "            'train_precision': float(train_precision), \n",
    "            'test_precision': float(test_precision),\n",
    "            '@k': int(k), \n",
    "            'runtime_min': float(runtime_min)},\n",
    "            ignore_index=True)\n",
    "        \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    figure, axis = plt.subplots()\n",
    "    figure.suptitle('Learning progress: precision @%s' %k)\n",
    "    axis.plot(stats['epochs'], stats['train_precision'], label='train')\n",
    "    axis.plot(stats['epochs'], stats['test_precision'], label='test')\n",
    "    axis.set_xlabel('Epochs')\n",
    "    axis.set_ylabel('Precision')\n",
    "    axis.legend()\n",
    "    \n",
    "    return(figure, stats, total_runtime_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_3 = learning_vis_precision(train, test, item_features, k=3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prec_at_5 = learning_vis_precision(train, test, item_features, k=5, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_5[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_10 = learning_vis_precision(train, test, item_features, k=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_10[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_10[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_10[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to regularize mnodel and achieve better results on test set by hyperparameter tuning.\n",
    "\n",
    "# The author of the LightFM package Maciej Kula has also developed the algorythm for hyperparameter tuning.\n",
    "# Original algorythm was posted on GitHub 23 Apr 2018.\n",
    "# Code is available via url https://gist.github.com/maciejkula/29aaf2db2efee5775a7f14dc387f0c0f\n",
    "\n",
    "# For the purposes of this project the original code was modified to meet the needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train set into train_train and validate subsets.\n",
    "\n",
    "(train_train, validate) = random_train_test_split(train, \n",
    "                                                  test_percentage=0.2, \n",
    "                                                  random_state=np.random.RandomState(2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC focused tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Improving AUC metric.\n",
    "\n",
    "\n",
    "def sample_hyperparameters():\n",
    "    \n",
    "    # Choose the hyperparameters to tune and the range of values.\n",
    "\n",
    "    while True:\n",
    "        yield {\n",
    "            'no_components': np.random.randint(10, 100),\n",
    "            'learning_schedule': np.random.choice(['adagrad', 'adadelta']),\n",
    "            'loss': np.random.choice(['logistic', 'bpr', 'warp', 'warp-kos']),\n",
    "            'k': np.random.randint(1, 10),\n",
    "            'n': np.random.randint(1, 20),\n",
    "            'learning_rate': np.random.exponential(0.005),\n",
    "            'item_alpha': np.random.exponential(1e-10),\n",
    "            'max_sampled': np.random.randint(5, 30),\n",
    "            'num_epochs': np.random.randint(10, 100)\n",
    "        }\n",
    "\n",
    "\n",
    "def random_search_auc(train_train, validate, num_samples=10, num_threads=4):\n",
    "    \n",
    "    # Randomly search for various combinations of hyperparameters.\n",
    "\n",
    "\n",
    "    for hyperparams in islice(sample_hyperparameters(), num_samples):\n",
    "        num_epochs = hyperparams.pop('num_epochs')\n",
    "\n",
    "        model_tuned = LightFM(**hyperparams)\n",
    "        model_tuned.fit(train_train, epochs=num_epochs, num_threads=num_threads)\n",
    "\n",
    "        ranking_score = auc_score(model_tuned, validate, train_interactions=train_train, \n",
    "                                  num_threads=num_threads).mean()\n",
    "\n",
    "        hyperparams['num_epochs'] = num_epochs\n",
    "        \n",
    "        yield (ranking_score, hyperparams, model_tuned)\n",
    "        # Returns: generator of (auc, hyperparameter dict, fitted model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    (ranking_score, hyperparams, model_tuned) = max(random_search_auc(train_train, validate), \n",
    "                                                    key=lambda x: x[0])\n",
    "\n",
    "    print('Best ranking score {} at {}'.format(ranking_score, hyperparams))\n",
    "    print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC: Tuned LightFM model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the tuned model.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model_hybrid = model_tuned\n",
    "\n",
    "model_hybrid.fit(train, \n",
    "                 item_features=item_features, \n",
    "                 epochs=hyperparams['num_epochs'], \n",
    "                 num_threads=4)\n",
    "\n",
    "print('Model trained in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned model evaluation (auc_score, precision_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_auc = auc_score(model_hybrid, \n",
    "                      train, \n",
    "                      item_features=item_features, \n",
    "                      num_threads=4).mean()\n",
    "\n",
    "print('Train AUC score: ', train_auc)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train interactions fill be also passed to avoid model re-recommending items to users.\n",
    "test_auc = auc_score(model_hybrid,\n",
    "                     test, \n",
    "                     item_features=item_features, \n",
    "                     train_interactions = train, \n",
    "                     num_threads=4).mean()\n",
    "\n",
    "print('Test AUC score: ', test_auc)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how the precision changes depending on parameter 'k'.\n",
    "\n",
    "def k_vis_precision(model, train, test, item_features, epochs):\n",
    "    \n",
    "    stats = pd.DataFrame(columns = ['@k', 'train_precision', 'test_precision', 'runtime_min'])\n",
    "    model_hybrid = model\n",
    "    \n",
    "    model_hybrid.fit(train, \n",
    "                     item_features=item_features, \n",
    "                     epochs=epochs, \n",
    "                     num_threads=4)  \n",
    "    \n",
    "    total_runtime_min = 0\n",
    "    \n",
    "    for k in range(1,51):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        \n",
    "        train_precision = precision_at_k(model_hybrid, \n",
    "                                         train,\n",
    "                                         item_features=item_features, \n",
    "                                         num_threads=4, \n",
    "                                         k=k).mean()\n",
    "\n",
    "        test_precision = precision_at_k(model_hybrid, \n",
    "                                        test,\n",
    "                                        item_features=item_features, \n",
    "                                        train_interactions = train, \n",
    "                                        num_threads=4, \n",
    "                                        k=k).mean()\n",
    "\n",
    "        runtime_min = round((time.time()-start_time)/60, 6)\n",
    "        total_runtime_min += runtime_min\n",
    "        \n",
    "        stats = stats.append({\n",
    "            '@k': int(k), \n",
    "            'train_precision': float(train_precision), \n",
    "            'test_precision': float(test_precision),\n",
    "            'runtime_min': float(runtime_min)},\n",
    "            ignore_index=True)\n",
    "        \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    figure, axis = plt.subplots()\n",
    "    figure.suptitle('Precision VS k')\n",
    "    axis.plot(stats['@k'], stats['train_precision'], label='train')\n",
    "    axis.plot(stats['@k'], stats['test_precision'], label='test')\n",
    "    axis.set_xlabel('@k')\n",
    "    axis.set_ylabel('Precision')\n",
    "    axis.legend()\n",
    "    \n",
    "    return(figure, stats, total_runtime_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_vis_precision_output = k_vis_precision(model_hybrid, train, test, item_features, epochs=hyperparams['num_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test precision separately to have a closer look at behaviour.\n",
    "\n",
    "figure, axis = plt.subplots()\n",
    "figure.suptitle('Precision VS k')\n",
    "axis.plot(k_vis_precision_output[1]['@k'], k_vis_precision_output[1]['test_precision'], label='test',color='orange')\n",
    "axis.set_xlabel('@k')\n",
    "axis.set_ylabel('Precision')\n",
    "axis.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vis_precision_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vis_precision[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision focused tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving precision_at_k metric.\n",
    "\n",
    "\n",
    "\n",
    "def random_search_precision(train_train, validate, num_samples=10, k=k, num_threads=4):\n",
    "    \n",
    "    # Randomly search for various combinations of hyperparameters.\n",
    "\n",
    "\n",
    "    for hyperparams in islice(sample_hyperparameters(), num_samples):\n",
    "        num_epochs = hyperparams.pop('num_epochs')\n",
    "\n",
    "        model_tuned = LightFM(**hyperparams)\n",
    "        model_tuned.fit(train_train, epochs=num_epochs, num_threads=num_threads)\n",
    "\n",
    "        ranking_score = precision_at_k(model_tuned, validate, train_interactions=train_train, \n",
    "                                       num_threads=num_threads, \n",
    "                                       k=k).mean()\n",
    "\n",
    "        hyperparams['num_epochs'] = num_epochs\n",
    "        \n",
    "        yield (ranking_score, hyperparams, model_tuned)\n",
    "        # Returns: generator of (precision_at_k, hyperparameter dict, fitted model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    (ranking_score, hyperparams, model_tuned) = max(random_search_precision(train_train, validate), \n",
    "                                                    key=lambda x: x[0])\n",
    "\n",
    "    print('Best presicion ranking score {} at {}'.format(ranking_score, hyperparams))\n",
    "    print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision: Tuned LightFM model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the tuned model.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model_hybrid = model_tuned\n",
    "\n",
    "model_hybrid.fit(train, \n",
    "                 item_features=item_features, \n",
    "                 epochs=hyperparams['num_epochs'], \n",
    "                 num_threads=4)\n",
    "\n",
    "print('Model trained in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned model evaluation (auc_score, precision_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_auc = auc_score(model_hybrid, \n",
    "                      train, \n",
    "                      item_features=item_features, \n",
    "                      num_threads=4).mean()\n",
    "\n",
    "print('Train AUC score: ', train_auc)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train interactions fill be also passed to avoid model re-recommending items to users.\n",
    "test_auc = auc_score(model_hybrid,\n",
    "                     test, \n",
    "                     item_features=item_features, \n",
    "                     train_interactions = train, \n",
    "                     num_threads=4).mean()\n",
    "\n",
    "print('Test AUC score: ', test_auc)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vis_precision_output = k_vis_precision(model_hybrid, train, test, item_features, epochs=hyperparams['num_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot test precision separately to have a closer look at behaviour.\n",
    "\n",
    "figure, axis = plt.subplots()\n",
    "figure.suptitle('Precision VS k')\n",
    "axis.plot(k_vis_precision_output[1]['@k'], k_vis_precision_output[1]['test_precision'], label='test',color='orange')\n",
    "axis.set_xlabel('@k')\n",
    "axis.set_ylabel('Precision')\n",
    "axis.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_vis_precision_output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly, offer recommendations of hybrid model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://making.lyst.com/lightfm/docs/quickstart.html?highlight=precision_at_k"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Recommedations algorythm was developed by the author of LightFM package, it is modified for current project.\n",
    "# https://making.lyst.com/lightfm/docs/quickstart.html?highlight=precision_at_k\n",
    "\n",
    "def recommend(model, data, users):\n",
    "    \n",
    "    '''\n",
    "    model - the model to be used for recommendations.\n",
    "    data - coo matrix of known positive interactions. For academic purposes - train set. For production - total.\n",
    "    users - list of users for recommendations\n",
    "    '''\n",
    "\n",
    "    n_users, n_items = data.shape\n",
    "\n",
    "    for user in users:\n",
    "        \n",
    "        positive_interactions = ?????????\n",
    "        \n",
    "        # model.predict(user_ids, item_ids, item_features=None, user_features=None, num_threads=1)\n",
    "        scores = model.predict(user, np.arange(n_items))\n",
    "        \n",
    "        recommeded_items = data['item_labels'][np.argsort(-scores)]\n",
    "\n",
    "        print('   User %s' % user)\n",
    "        print('   Positive interactions:')\n",
    "\n",
    "        for interaction in positive_interactions[:3]:\n",
    "            print('%s' % interaction)\n",
    "\n",
    "        print('   Recommended:')\n",
    "\n",
    "        for item in recommeded_items[:3]:\n",
    "            print('%s' % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondly, offer recommendations based on bought together items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another section of recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 6. https://www.kdd.org/exploration_files/19-1-Article3.pdf\n",
    "\n",
    "How to test in production https://ieeexplore.ieee.org/abstract/document/1611624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
