{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import coo_matrix  # LightFM fit method requires coo matrix format as input.\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightfm.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import and Cleaning - Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing Events data and sorting by timestamp column which corresponds the historical order of events.\n",
    "\n",
    "df_events = pd.read_csv(\"events.csv\")\n",
    "df_events = df_events.sort_values(by=['timestamp'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View on the ratio between different types of events.\n",
    "sns.countplot(x='event', data=df_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.event.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Events types “view”, “addtocart”, “transaction” are the implicit customer feedback.\n",
    "# They can be considered as rating and will be transformed from categorical to numerical format.\n",
    "\n",
    "# The weights are subject to tuning together with hyperparameters to achieve better performance.\n",
    "# Initial weights: view=1, add to cart=2, purchase=3.\n",
    "\n",
    "weight_view = 1\n",
    "weight_addtocart = 2\n",
    "weight_transaction = 3\n",
    "\n",
    "df_events.event.replace(to_replace=dict(\n",
    "    view=weight_view, addtocart=weight_addtocart, transaction=weight_transaction), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now the events replaced with corresponding weights.\n",
    "df_events.event.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !!!!!\n",
    "# Select only the rows which are PURCHASE.\n",
    "# df_events = df_events.loc[df_events['event'] == weight_transaction].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.event.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_users = df_events['visitorid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use timestamps for split which mimics the real-life case as the events are sorted in historical order.\n",
    "# Split ratio is 80% for train set, and 20% for test set.\n",
    "\n",
    "split_point = int(np.ceil(len(df_events)*0.8))  # Index of split point.\n",
    "split_point_time = int(df_events.loc[split_point]['timestamp'])  # Timestamp of split point.\n",
    "\n",
    "df_events_train = df_events.loc[0:split_point]\n",
    "df_events_test = df_events.loc[split_point+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_events_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train / Test split\n",
    "\n",
    "# Use timestamps for split which mimics the real-life case as the events are sorted in historical order.\n",
    "# Split ratio is 80% for train set, and 20% for test set.\n",
    "\n",
    "split_point = int(np.ceil(len(df_events)*0.8))  # Index of split point.\n",
    "split_point_time = int(df_events.loc[split_point]['timestamp'])  # Timestamp of split point.\n",
    "\n",
    "df_events_train = df_events.loc[0:split_point]\n",
    "df_events_test = df_events.loc[split_point+1:]\n",
    "\n",
    "df_events_train.info()\n",
    "print()\n",
    "df_events_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LightFM datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation purposes (auc_score) dimensionality of train/test interaction matrices should be the same.\n",
    "# In order to achieve this, need to create mapping for all users and all items.\n",
    "# Then separately for train and test - the interactions will be filled in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping.\n",
    "\n",
    "# The fit method of class Dataset takes the list of all the visitors and items.\n",
    "# The implementation allows to ignore duplicates.\n",
    "\n",
    "# Train set mapping.\n",
    "dataset_train = Dataset()\n",
    "dataset_train.fit(\n",
    "    df_events['visitorid'].to_numpy(),\n",
    "    df_events['itemid'].to_numpy()\n",
    ")\n",
    "\n",
    "# Train set mapping.\n",
    "dataset_test = Dataset()\n",
    "dataset_test.fit(\n",
    "    df_events['visitorid'].to_numpy(),\n",
    "    df_events['itemid'].to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform interactions in required format.\n",
    "\n",
    "# Dataset class has the method build_interactions that allows to fill in the matrix created at previous step.\n",
    "# As the input for this method need to pass the list of tuples (visitorid, itemid, weight).\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train set interactions transformed.\n",
    "df_events_train_interactions = []\n",
    "for index, row in df_events_train.iterrows():\n",
    "    df_events_train_interactions.append((int(row['visitorid']), int(row['itemid']), row['event']))\n",
    "    \n",
    "# Test set interactions transformed.\n",
    "df_events_test_interactions = []\n",
    "for index, row in df_events_test.iterrows():\n",
    "    df_events_test_interactions.append((int(row['visitorid']), int(row['itemid']), row['event']))\n",
    "    \n",
    "print('Finished in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Check original VS transformed length TRAIN: ', \n",
    "     len(df_events_train),\n",
    "     ' / ',\n",
    "     len(df_events_train_interactions))\n",
    "\n",
    "print('Check original VS transformed length TEST: ', \n",
    "     len(df_events_test),\n",
    "     ' / ',\n",
    "     len(df_events_test_interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build interactions matrix for train and test sets\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "(interactions_train, weights_train) = dataset_train.build_interactions(df_events_train_interactions)\n",
    "(interactions_test, weights_test) = dataset_test.build_interactions(df_events_test_interactions)\n",
    "\n",
    "print('Finished in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model without item features first. This will mean collaboration based predictions.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = LightFM(no_components=500, loss='warp')\n",
    "model.fit(weights_train, epochs=20, num_threads=4)\n",
    "\n",
    "print('Model trained in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation (auc_score, precision_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_auc = auc_score(model, weights_train).mean()\n",
    "\n",
    "print('Train AUC score: ', train_auc)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_auc = auc_score(model, weights_test).mean()\n",
    "\n",
    "print('Test AUC score: ', test_auc)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "train_precision = precision_at_k(model, weights_train, k=10).mean()\n",
    "print('Train precision for k=10: ', train_precision)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "test_precision = precision_at_k(model, weights_test, k=10).mean()\n",
    "print('Test precision for k=10: ', test_precision)\n",
    "print('Calculated in: ', round((time.time()-start_time)/60, 2), \" minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
